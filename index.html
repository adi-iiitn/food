<!DOCTYPE html>
<html lang="en">

<head>
  <title>AI Object Detection Professional</title>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <!-- Materialize CSS -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/materialize/1.0.0/css/materialize.min.css" rel="stylesheet" />
  <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;600&display=swap" rel="stylesheet" />
  <style>
    body {
      font-family: 'Poppins', sans-serif;
      background: #f9f9f9;
      margin: 0;
      padding: 0;
      text-align: center;
      min-height: 100vh;
      display: flex;
      flex-direction: column;
    }

    header {
      background-color: #2196f3;
      color: white;
      padding: 15px 0;
      font-weight: 600;
      font-size: 1.8rem;
      box-shadow: 0 2px 6px rgba(33, 150, 243, 0.4);
    }

    main {
      flex: 1;
      padding: 20px;
      max-width: 900px;
      margin: auto;
      width: 90vw;
    }

    #video,
    #c1 {
      width: 100%;
      max-height: 60vh;
      border-radius: 12px;
      border: 2px solid #2196f3;
      box-shadow: 0 4px 10px rgba(33, 150, 243, 0.3);
      background: black;
      object-fit: contain;
    }

    #loadingText {
      font-weight: 600;
      color: #555;
      margin-bottom: 20px;
      min-height: 24px;
    }

    .controls {
      margin-top: 25px;
      display: flex;
      flex-wrap: wrap;
      justify-content: center;
      gap: 15px;
    }

    .control-group {
      background: white;
      padding: 12px 20px;
      border-radius: 10px;
      box-shadow: 0 2px 6px rgba(0, 0, 0, 0.1);
      min-width: 150px;
      flex-grow: 1;
      max-width: 300px;
      text-align: left;
    }

    label {
      font-weight: 600;
    }

    #detectionsList {
      margin-top: 20px;
      text-align: left;
      max-height: 150px;
      overflow-y: auto;
      background: white;
      padding: 15px;
      border-radius: 10px;
      box-shadow: 0 2px 6px rgba(0, 0, 0, 0.1);
      font-size: 0.9rem;
    }

    #detectionsList ul {
      padding-left: 18px;
      margin: 0;
    }

    footer {
      padding: 15px 10px;
      background-color: #2196f3;
      color: white;
      font-weight: 600;
      box-shadow: 0 -2px 6px rgba(33, 150, 243, 0.4);
      margin-top: auto;
    }

    .btn-custom {
      background-color: #1976d2 !important;
      color: white !important;
      width: 100%;
    }

    @media (max-width: 600px) {
      .controls {
        flex-direction: column;
      }
    }
  </style>
</head>

<body>
  <header>AI Object Detection Pro</header>

  <main>
    <div id="loadingText">Initializing camera and AI model...</div>

    <!-- Video hidden for direct feed, canvas shows output -->
    <video id="video" playsinline autoplay muted style="display:none;"></video>
    <canvas id="c1"></canvas>

    <div class="controls">
      <div class="control-group">
        <label for="aiToggle">Enable AI Detection</label>
        <div class="switch">
          <label>
            Off
            <input type="checkbox" id="aiToggle" disabled />
            <span class="lever"></span>
            On
          </label>
        </div>
      </div>

      <div class="control-group">
        <label for="fpsRange">FPS: <span id="fpsValue">10</span></label>
        <p class="range-field">
          <input type="range" id="fpsRange" min="1" max="30" value="10" />
        </p>
      </div>

      <div class="control-group">
        <label for="confidenceRange">Confidence Threshold: <span id="confValue">0.5</span></label>
        <p class="range-field">
          <input type="range" id="confidenceRange" min="0" max="1" step="0.05" value="0.5" />
        </p>
      </div>

      <div class="control-group">
        <label for="cameraSelect">Camera</label>
        <select id="cameraSelect" class="browser-default" disabled>
          <option value="user">Front Camera</option>
          <option value="environment" selected>Back Camera</option>
        </select>
      </div>

      <div class="control-group">
        <button id="toggleCameraBtn" class="btn btn-custom">Turn Camera Off</button>
      </div>

      <div class="control-group">
        <button id="captureBtn" class="btn btn-custom">Capture Snapshot</button>
      </div>
    </div>

    <div id="detectionsList">
      <strong>Detected Objects:</strong>
      <ul id="objectsUl">
        <li>No objects detected yet.</li>
      </ul>
    </div>
  </main>

  <footer>Made with ❤️ by AI Enthusiasts using ml5.js & TensorFlow.js</footer>

  <script src="https://unpkg.com/ml5@0.12.2/dist/ml5.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/1.0.0/js/materialize.min.js"></script>
  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('c1');
    const ctx = canvas.getContext('2d');
    const loadingText = document.getElementById('loadingText');

    const aiToggle = document.getElementById('aiToggle');
    const fpsRange = document.getElementById('fpsRange');
    const fpsValue = document.getElementById('fpsValue');
    const confidenceRange = document.getElementById('confidenceRange');
    const confValue = document.getElementById('confValue');
    const cameraSelect = document.getElementById('cameraSelect');
    const toggleCameraBtn = document.getElementById('toggleCameraBtn');
    const captureBtn = document.getElementById('captureBtn');

    const objectsUl = document.getElementById('objectsUl');

    let model, detections = [];
    let modelIsLoaded = false;
    let aiEnabled = false;
    let lastDetectionTime = 0;
    let fps = parseInt(fpsRange.value);
    let confidenceThreshold = parseFloat(confidenceRange.value);
    let currentStream = null;
    let cameraOn = true;

    // Initialize camera with selected facingMode
    async function setupCamera(facingMode = 'environment') {
      if (currentStream) {
        currentStream.getTracks().forEach(track => track.stop());
      }
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: facingMode },
          audio: false
        });
        currentStream = stream;
        video.srcObject = stream;
        await video.play();

        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;

        loadingText.textContent = 'Camera started. Loading AI model...';
        cameraSelect.disabled = false;
        toggleCameraBtn.textContent = 'Turn Camera Off';
        cameraOn = true;
      } catch (err) {
        loadingText.textContent = 'Error accessing camera: ' + err.message;
        cameraSelect.disabled = true;
        toggleCameraBtn.disabled = true;
        console.error(err);
      }
    }

    // Load the object detection model
    function loadModel() {
      loadingText.textContent = 'Loading AI model...';
      ml5.objectDetector('cocossd')
        .then(loadedModel => {
          model = loadedModel;
          modelIsLoaded = true;
          loadingText.textContent = 'Model loaded. Enable AI detection.';
          aiToggle.disabled = false;
        })
        .catch(err => {
          loadingText.textContent = 'Error loading model: ' + err.message;
          console.error(err);
        });
    }

    // Draw video and detections on canvas
    function drawCanvas() {
      if (!video.videoWidth) return;

      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;

      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      if (aiEnabled && detections.length > 0) {
        detections.forEach(det => {
          if (det.confidence >= confidenceThreshold) {
            ctx.strokeStyle = '#2196f3';
            ctx.lineWidth = 3;
            ctx.font = '16px Poppins';
            ctx.fillStyle = '#2196f3';

            ctx.beginPath();
            ctx.rect(det.x, det.y, det.width, det.height);
            ctx.stroke();

            ctx.fillText(
              `${det.label} ${(det.confidence * 100).toFixed(1)}%`,
              det.x + 5,
              det.y > 20 ? det.y - 5 : det.y + 20
            );
          }
        });
      }
    }

    // Update detections list below canvas
    function updateDetectionsList() {
      objectsUl.innerHTML = '';
      if (aiEnabled && detections.length > 0) {
        detections.forEach(det => {
          if (det.confidence >= confidenceThreshold) {
            const li = document.createElement('li');
            li.textContent = `${det.label} — ${(det.confidence * 100).toFixed(1)}% confidence`;
            objectsUl.appendChild(li);
          }
        });
      }
      if (objectsUl.children.length === 0) {
        objectsUl.innerHTML = '<li>No objects detected above threshold.</li>';
      }
    }

    // Detection loop based on FPS setting
    async function detectionLoop() {
      if (!modelIsLoaded || !aiEnabled || !cameraOn) {
        drawCanvas();
        requestAnimationFrame(detectionLoop);
        return;
      }

      const now = performance.now();
      if (now - lastDetectionTime > (1000 / fps)) {
        try {
          const results = await model.detect(video);
          detections = results;
          lastDetectionTime = now;
          updateDetectionsList();
        } catch (error) {
          console.error('Detection error:', error);
          loadingText.textContent = 'Detection error: ' + error.message;
        }
      }

      drawCanvas();
      requestAnimationFrame(detectionLoop);
    }

    // Event handlers
    aiToggle.addEventListener('change', () => {
      aiEnabled = aiToggle.checked;
      if (!aiEnabled) {
        detections = [];
        updateDetectionsList();
        drawCanvas();
      }
    });

    fpsRange.addEventListener('input', () => {
      fps = parseInt(fpsRange.value);
      fpsValue.textContent = fps;
    });

    confidenceRange.addEventListener('input', () => {
      confidenceThreshold = parseFloat(confidenceRange.value);
      confValue.textContent = confidenceThreshold.toFixed(2);
      updateDetectionsList();
    });

    cameraSelect.addEventListener('change', () => {
      setupCamera(cameraSelect.value);
    });

    toggleCameraBtn.addEventListener('click', () => {
      if (cameraOn) {
        if (currentStream) {
          currentStream.getTracks().forEach(track => track.stop());
        }
        loadingText.textContent = 'Camera is off';
        cameraOn = false;
        toggleCameraBtn.textContent = 'Turn Camera On';
        aiToggle.disabled = true;
        aiToggle.checked = false;
        aiEnabled = false;
        detections = [];
        updateDetectionsList();
        ctx.clearRect(0, 0, canvas.width, canvas.height);
      } else {
        setupCamera(cameraSelect.value);
        loadingText.textContent = 'Camera restarting...';
        aiToggle.disabled = !modelIsLoaded;
        toggleCameraBtn.textContent = 'Turn Camera Off';
        cameraOn = true;
      }
    });

    captureBtn.addEventListener('click', () => {
      const image = canvas.toDataURL('image/png');
      const link = document.createElement('a');
      link.href = image;
      link.download = `snapshot_${Date.now()}.png`;
      document.body.appendChild(link);
      link.click();
      document.body.removeChild(link);
    });

    // Start everything
    (async () => {
      await setupCamera(cameraSelect.value);
      loadModel();
      detectionLoop();
    })();
  </script>
</body>

</html>
